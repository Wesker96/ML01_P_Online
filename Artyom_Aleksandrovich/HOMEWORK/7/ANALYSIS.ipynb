{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки для анализа данных и визуализации. pandas для работы с таблицами, numpy для числовых операций, stats из scipy для статистических тестов, seaborn и matplotlib.pyplot для построения графиков, MinMaxScaler из sklearn.preprocessing для масштабирования данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных из файла credit_train.csv с указанием разделителя ;, десятичного знака , и кодировки windows-1251."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('credit_train.csv', sep=';', decimal=',', encoding='windows-1251')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем строки с пропусками данных (NaN), чтобы избежать проблем при дальнейшей обработке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбираем только числовые столбцы из датафрейма для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем Z-оценки для числовых значений и удаляем строки с выбросами (где Z-оценка больше 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "numeric_df_no_outliers = numeric_df[(z_scores < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем корреляционную матрицу для числовых данных без выбросов и визуализируем её с помощью тепловой карты (heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numeric_df_no_outliers.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title(\"Корреляционная матрица\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем случайную выборку данных для визуализации зависимостей между переменными. Строим графики зависимостей с помощью seaborn.pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = min(1000, len(numeric_df_no_outliers))\n",
    "sampled_data = numeric_df_no_outliers.sample(n=sample_size, random_state=1)\n",
    "sns.pairplot(sampled_data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем тест Шапиро-Уилка для проверки нормальности распределения и выполняем его для каждого числового столбца. Выводим результаты теста и делаем выводы о нормальности распределения на основе p-значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "for column in numeric_df_no_outliers.columns:\n",
    "    stat, p = shapiro(numeric_df_no_outliers[column])\n",
    "    print(f'{column}: p-value={p}')\n",
    "    if p > 0.05:\n",
    "        print(f'Колонка {column} имеет нормальное распределение\\n')\n",
    "    else:\n",
    "        print(f'Колонка {column} не имеет нормального распределения\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабируем данные с использованием Min-Max нормализации (преобразуем значения в диапазон [0, 1]). Создаем новый датафрейм из масштабированных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_df_no_outliers)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=numeric_df_no_outliers.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем масштабированные данные в новый CSV-файл credit_train_processed.csv без индексов строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv('credit_train_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Обработка данных и оценка выбросов\n",
    "Код: Мы загрузили данные, удалили строки с пропусками, отобрали числовые столбцы и удалили выбросы с помощью Z-оценок.\n",
    "\n",
    "Вывод: После обработки данные стали чище и более пригодными для анализа, так как выбросы, которые могли искажать результаты, были удалены.\n",
    "\n",
    "2. Корреляционная матрица\n",
    "Код: Мы вычислили корреляционную матрицу для числовых данных без выбросов и визуализировали её с помощью тепловой карты.\n",
    "\n",
    "График: Тепловая карта показывает степень взаимосвязи между переменными. Значения корреляции варьируются от -1 до 1, где значения ближе к 1 или -1 указывают на сильную корреляцию (положительную или отрицательную), а значения ближе к 0 указывают на слабую или отсутствующую корреляцию.\n",
    "\n",
    "Вывод: Матрица корреляции позволяет выявить, какие переменные имеют сильные взаимосвязи. Это может быть полезно для выбора признаков и дальнейшего анализа. Если на графике есть переменные с высокой корреляцией (ближе к 1 или -1), это может свидетельствовать о линейной зависимости между ними.\n",
    "\n",
    "3. Графики зависимостей\n",
    "Код: Мы построили графики зависимостей между числовыми переменными с использованием функции sns.pairplot.\n",
    "\n",
    "График: Графики зависимостей позволяют визуализировать отношения между различными парами переменных. Они могут показать, как изменяются данные и есть ли явные тренды или кластеры.\n",
    "\n",
    "Вывод: Графики зависимостей помогают выявить паттерны в данных, такие как линейные или нелинейные зависимости, а также могут показать наличие выбросов или необычных точек данных.\n",
    "\n",
    "4. Тест на нормальность распределения\n",
    "Код: Мы выполнили тест Шапиро-Уилка для проверки нормальности распределения числовых столбцов.\n",
    "\n",
    "Результаты: Тест Шапиро-Уилка для каждой переменной выводит p-значение, которое показывает, имеет ли переменная нормальное распределение.\n",
    "\n",
    "Если p-значение > 0.05, то переменная имеет нормальное распределение.\n",
    "\n",
    "Если p-значение ≤ 0.05, то переменная не имеет нормального распределения.\n",
    "\n",
    "Вывод: Результаты теста на нормальность распределения важны для выбора методов анализа. Многие статистические методы предполагают нормальное распределение данных.\n",
    "\n",
    "5. Масштабирование данных\n",
    "Код: Мы масштабировали данные с использованием Min-Max нормализации.\n",
    "\n",
    "Вывод: Масштабирование данных преобразовало все значения в диапазон [0, 1], что упростит дальнейший анализ и обучение моделей машинного обучения.\n",
    "\n",
    "Общий вывод\n",
    "Наш анализ показал, что после обработки и очистки данных мы получили более качественный набор данных для дальнейшего анализа. Корреляционная матрица и графики зависимостей помогли выявить взаимосвязи между переменными. Тест на нормальность распределения показал, какие переменные имеют нормальное распределение, что важно для выбора методов анализа. Масштабирование данных привело значения переменных к единому масштабу, что улучшит их использование в дальнейших расчетах и моделировании."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
