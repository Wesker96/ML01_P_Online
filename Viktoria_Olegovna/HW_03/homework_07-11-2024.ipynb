{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузить файл длиной не менее 2000 символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file, read file, get length, print length, return file content\n",
    "def load_file(filepath: str):\n",
    "    with open(filepath, 'r') as f:\n",
    "        file_content = f.read()\n",
    "        symbols_count = len(file_content)\n",
    "        print(f'File contains {symbols_count} symbols')\n",
    "\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contains 2166 symbols\n"
     ]
    }
   ],
   "source": [
    "filepath = 'text-file.txt'\n",
    "file_text = load_file(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Составить программу, которая считает число уникальных слов в тексте (без критерия\n",
    "схожести)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to exclude non-akphabetic and non-spaces symbols \n",
    "from string import punctuation\n",
    "\n",
    "# check that symbol is not punctuation sign\n",
    "def is_target_symbol(symbol: str):\n",
    "    return symbol not in punctuation\n",
    "\n",
    "# exclude unnecessary symbols from text, split to words, make set of words, get set length\n",
    "def calc_unique_words(text: str):\n",
    "    words = ''.join(filter(is_target_symbol, text.lower())).split()\n",
    "    uniques_count = len(set(words))\n",
    "    print(f'There are {uniques_count} unique words in text')\n",
    "\n",
    "    return uniques_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 214 unique words in text\n"
     ]
    }
   ],
   "source": [
    "uniques_count = calc_unique_words(file_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Составить программу, которая считает число гласных и согласных букв."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through string and check if symbol in vowels string\n",
    "# if symbol is non-vowel but alphabetic - it's consonant\n",
    "def calculate_letters(string: str):\n",
    "    vowels = 'aeiou'\n",
    "    vowels_count, consonants_count = 0, 0\n",
    "\n",
    "    for symbol in string:\n",
    "        if symbol in vowels or symbol.lower() in vowels:\n",
    "            vowels_count += 1\n",
    "        elif symbol.isalpha():\n",
    "            consonants_count += 1\n",
    "\n",
    "    return vowels_count, consonants_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vowels count - 656, consonats count - 1054\n"
     ]
    }
   ],
   "source": [
    "vowels, consonants = calculate_letters(file_text)\n",
    "print(f'Vowels count - {vowels}, consonats count - {consonants}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Составить программу, которая считает число предложений, их длину и число (количество)\n",
    "раз использования каждого слова в тексте (с критерием схожести, критерий схожести слов\n",
    "выбрать самостоятельно, например, spacy (en_core_web_sm) или расстояние\n",
    "Левенштейна)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Вывести 10 наиболее часто встречаемых слов. \n",
    "P.S. Рекомендую перед решением задания проанализировать задачу и обосновать\n",
    "алгоритм ее решения в текстовом виде. В процессе написания кода использовать\n",
    "комментарии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчета предложений в тексте убираются точки из распространенных сокращений \"Mrs.\", \"Mr.\" Заменяются другие знаки окончания предложения (\"!\", \"?\") на точку для упрощения разделения текста на предложения. Текст режется на предложения по разделителю \".\", предложения делятся на слова. Для предложений, содержащих слова, выводится кол-во слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate count of sentences and words in each one\n",
    "def proc_sentences(string: str):\n",
    "    # replace reduction to exclide point\n",
    "    for reduction in ['Mrs.', 'Mr.']:\n",
    "        proc_str = string.replace(reduction, reduction[:-1])\n",
    "\n",
    "    # replace other sentences separators to simplify spliting by point\n",
    "    for separator in ['!', '?']:\n",
    "        proc_str = proc_str.replace(separator, '.')\n",
    "\n",
    "    sentences_list = proc_str.split('.')\n",
    "    sentences_count = 0\n",
    "\n",
    "    for item in sentences_list:\n",
    "        item = item.strip()\n",
    "\n",
    "        if item:        \n",
    "            sentences_count += 1\n",
    "            sentence_length = len(item.split())\n",
    "            print('Sentence:\\n', item, '\\nWords count -', sentence_length, '\\n\\n')\n",
    "\n",
    "    print('Sentences count -', sentences_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contains 2166 symbols\n",
      "Sentence:\n",
      " It details the story of a girl named Alice who falls through a rabbit hole into a fantasy world of anthropomorphic creatures \n",
      "Words count - 22 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " It is seen as an example of the literary nonsense genre \n",
      "Words count - 11 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " The artist John Tenniel provided 42 wood-engraved illustrations for the book \n",
      "Words count - 11 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " It received positive reviews upon release and is now one of the best-known works of Victorian literature; its narrative, structure, characters and imagery have had a widespread influence on popular culture and literature, especially in the fantasy genre \n",
      "Words count - 38 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " It is credited as helping end an era of didacticism in children's literature, inaugurating an era in which writing for children aimed to \"delight or entertain\" \n",
      "Words count - 26 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " The tale plays with logic, giving the story lasting popularity with adults as well as with children \n",
      "Words count - 17 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " The titular character Alice shares her name with Alice Liddell, a girl Carroll knew-cholars disagree about the extent to which the character was based upon her \n",
      "Words count - 26 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " The book has never been out of print and has been translated into 174 languages \n",
      "Words count - 15 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " Its legacy includes adaptations to screen, radio, visual art, ballet, opera, and musical theatre, as well as theme parks, board games and video games \n",
      "Words count - 24 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " Carroll published a sequel in 1871 entitled Through the Looking-Glass and a shortened version for young children, The Nursery \"Alice\", in 1890 \n",
      "Words count - 22 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " Alice's Adventures in Wonderland was conceived on 4 July 1862, when Lewis Carroll and Reverend Robinson Duckworth rowed up the river Isis with the three young daughters of Carroll's friend Henry Liddell: Lorina Charlotte (aged 13; \"Prima\" in the book's prefatory verse); Alice Pleasance (aged 10; \"Secunda\" in the verse); and Edith Mary (aged 8; \"Tertia\" in the verse) \n",
      "Words count - 59 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " The journey began at Folly Bridge, Oxford, and ended 5 miles (8 km) upstream at Godstow, Oxfordshire \n",
      "Words count - 17 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " During the trip, Carroll told the girls a story that he described in his diary as \"Alice's Adventures Under Ground\", which his journal says he \"undertook to write out for Alice\" \n",
      "Words count - 31 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " Alice Liddell recalled that she asked Carroll to write it down: unlike other stories he had told her, this one she wanted to preserve \n",
      "Words count - 24 \n",
      "\n",
      "\n",
      "Sentence:\n",
      " She finally received the manuscript more than two years later \n",
      "Words count - 10 \n",
      "\n",
      "\n",
      "Sentences count - 15\n"
     ]
    }
   ],
   "source": [
    "file_text = load_file(filepath)\n",
    "proc_sentences(file_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подсчета уникальных слов в тексте с критерием схожести сначала убираются знаки пунктуации. Текст (в нижнем регистре) разделяется на токены с помощью библиотеки spacy (легкая моделька en_core_web_sm). Составляется словарь: в качестве ключей - слова в первоначальной форме (с помощью spacy), значений - кол-ва вхождений слов-ключей в текст. Проверяется выделение символов '\\n', '\\t', '\\s' в отдельный токен с последующем его игнорированием. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выделения начальной формы слова можно было бы применять библиотеку nltk, в которой есть возможности определять корневую форму слова (stemming) или действительную форму слова (lemmatization), однако эти методы плохо работают с глаголами, предлогами и местоимениями. В библиотеке word_forms тоже есть возможность выделять начальную форму слова, но недостатками является отсутствие большого количества слов в ее словаре, а также низкое качество работы на предлогах. Методы сравнения слов по косинусному сходству и расстоянию Левенштейна являются менее обобщенными из-за необходимости подбирать и устанавливать пороги, чтобы считать слова схожими. Эти методы подошли бы больше для целенаправленного поиска максимально похожего слова для заданного. Библиотека spacy определяет начальные формы слов качественнее, поэтому используется для решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, whitespace\n",
    "import spacy\n",
    "\n",
    "# find unique words count with spacy\n",
    "def spacy_algorithm(text: str):\n",
    "    # replace punctuation symbols in lowercase text, create tokens from text\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    text_no_punct = text.lower().translate(translator)\n",
    "\n",
    "    npl = spacy.load('en_core_web_sm')\n",
    "    tokens = npl(text_no_punct)\n",
    "\n",
    "    unique_text_words = dict()\n",
    "    # fill dictionary with unique words, if word is't in word separators\n",
    "    for token in tokens:\n",
    "        if token.text not in whitespace:\n",
    "            unique_text_words[token.lemma_] = unique_text_words[token.lemma_] + 1 if token.lemma_ in unique_text_words.keys() else 1\n",
    "\n",
    "    unique_text_words = dict(sorted(unique_text_words.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    print(f'Unique words count is {len(unique_text_words)}')\n",
    "    print('Words used in text:')\n",
    "    for item in unique_text_words.items():\n",
    "        print(item)\n",
    "\n",
    "    return unique_text_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contains 2166 symbols\n",
      "Unique words count is 201\n",
      "Words used in text:\n",
      "('the', 23)\n",
      "('and', 10)\n",
      "('in', 10)\n",
      "('alice', 9)\n",
      "('of', 8)\n",
      "('a', 8)\n",
      "('be', 7)\n",
      "('as', 7)\n",
      "('to', 6)\n",
      "('carroll', 6)\n",
      "('it', 5)\n",
      "('have', 5)\n",
      "('with', 5)\n",
      "('she', 5)\n",
      "('story', 4)\n",
      "('for', 4)\n",
      "('girl', 3)\n",
      "('an', 3)\n",
      "('book', 3)\n",
      "('literature', 3)\n",
      "('character', 3)\n",
      "('which', 3)\n",
      "('write', 3)\n",
      "('child', 3)\n",
      "('liddell', 3)\n",
      "('age', 3)\n",
      "('verse', 3)\n",
      "('he', 3)\n",
      "('name', 2)\n",
      "('through', 2)\n",
      "('into', 2)\n",
      "('fantasy', 2)\n",
      "('genre', 2)\n",
      "('receive', 2)\n",
      "('upon', 2)\n",
      "('one', 2)\n",
      "('its', 2)\n",
      "('on', 2)\n",
      "('end', 2)\n",
      "('era', 2)\n",
      "('well', 2)\n",
      "('out', 2)\n",
      "('game', 2)\n",
      "('young', 2)\n",
      "('adventure', 2)\n",
      "('8', 2)\n",
      "('at', 2)\n",
      "('tell', 2)\n",
      "('that', 2)\n",
      "('his', 2)\n",
      "('detail', 1)\n",
      "('who', 1)\n",
      "('fall', 1)\n",
      "('rabbit', 1)\n",
      "('hole', 1)\n",
      "('world', 1)\n",
      "('anthropomorphic', 1)\n",
      "('creature', 1)\n",
      "('see', 1)\n",
      "('example', 1)\n",
      "('literary', 1)\n",
      "('nonsense', 1)\n",
      "('artist', 1)\n",
      "('john', 1)\n",
      "('tenniel', 1)\n",
      "('provide', 1)\n",
      "('42', 1)\n",
      "('woodengrave', 1)\n",
      "('illustration', 1)\n",
      "('positive', 1)\n",
      "('review', 1)\n",
      "('release', 1)\n",
      "('now', 1)\n",
      "('bestknown', 1)\n",
      "('work', 1)\n",
      "('victorian', 1)\n",
      "('narrative', 1)\n",
      "('structure', 1)\n",
      "('imagery', 1)\n",
      "('widespread', 1)\n",
      "('influence', 1)\n",
      "('popular', 1)\n",
      "('culture', 1)\n",
      "('especially', 1)\n",
      "('credit', 1)\n",
      "('help', 1)\n",
      "('didacticism', 1)\n",
      "('children', 1)\n",
      "('inaugurate', 1)\n",
      "('aim', 1)\n",
      "('delight', 1)\n",
      "('or', 1)\n",
      "('entertain', 1)\n",
      "('tale', 1)\n",
      "('play', 1)\n",
      "('logic', 1)\n",
      "('give', 1)\n",
      "('last', 1)\n",
      "('popularity', 1)\n",
      "('adult', 1)\n",
      "('titular', 1)\n",
      "('share', 1)\n",
      "('her', 1)\n",
      "('knewcholar', 1)\n",
      "('disagree', 1)\n",
      "('about', 1)\n",
      "('extent', 1)\n",
      "('base', 1)\n",
      "('never', 1)\n",
      "('print', 1)\n",
      "('translate', 1)\n",
      "('174', 1)\n",
      "('language', 1)\n",
      "('legacy', 1)\n",
      "('include', 1)\n",
      "('adaptation', 1)\n",
      "('screen', 1)\n",
      "('radio', 1)\n",
      "('visual', 1)\n",
      "('art', 1)\n",
      "('ballet', 1)\n",
      "('opera', 1)\n",
      "('musical', 1)\n",
      "('theatre', 1)\n",
      "('theme', 1)\n",
      "('park', 1)\n",
      "('board', 1)\n",
      "('video', 1)\n",
      "('publish', 1)\n",
      "('sequel', 1)\n",
      "('1871', 1)\n",
      "('entitle', 1)\n",
      "('lookingglass', 1)\n",
      "('shorten', 1)\n",
      "('version', 1)\n",
      "('nursery', 1)\n",
      "('1890', 1)\n",
      "('wonderland', 1)\n",
      "('conceive', 1)\n",
      "('4', 1)\n",
      "('july', 1)\n",
      "('1862', 1)\n",
      "('when', 1)\n",
      "('lewis', 1)\n",
      "('reverend', 1)\n",
      "('robinson', 1)\n",
      "('duckworth', 1)\n",
      "('row', 1)\n",
      "('up', 1)\n",
      "('river', 1)\n",
      "('isis', 1)\n",
      "('three', 1)\n",
      "('daughter', 1)\n",
      "('friend', 1)\n",
      "('henry', 1)\n",
      "('lorina', 1)\n",
      "('charlotte', 1)\n",
      "('13', 1)\n",
      "('prima', 1)\n",
      "('prefatory', 1)\n",
      "('pleasance', 1)\n",
      "('10', 1)\n",
      "('secunda', 1)\n",
      "('edith', 1)\n",
      "('mary', 1)\n",
      "('tertia', 1)\n",
      "('journey', 1)\n",
      "('begin', 1)\n",
      "('folly', 1)\n",
      "('bridge', 1)\n",
      "('oxford', 1)\n",
      "('5', 1)\n",
      "('mile', 1)\n",
      "('km', 1)\n",
      "('upstream', 1)\n",
      "('godstow', 1)\n",
      "('oxfordshire', 1)\n",
      "('during', 1)\n",
      "('trip', 1)\n",
      "('describe', 1)\n",
      "('diary', 1)\n",
      "('under', 1)\n",
      "('ground', 1)\n",
      "('journal', 1)\n",
      "('say', 1)\n",
      "('undertake', 1)\n",
      "('recall', 1)\n",
      "('ask', 1)\n",
      "('down', 1)\n",
      "('unlike', 1)\n",
      "('other', 1)\n",
      "('this', 1)\n",
      "('want', 1)\n",
      "('preserve', 1)\n",
      "('finally', 1)\n",
      "('manuscript', 1)\n",
      "('more', 1)\n",
      "('than', 1)\n",
      "('two', 1)\n",
      "('year', 1)\n",
      "('later', 1)\n"
     ]
    }
   ],
   "source": [
    "file_text = load_file(filepath)\n",
    "spacy_unique_words = spacy_algorithm(file_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, среди часто встречаемых в тексте много слов, не несущих смысловой нагрузки, удаялем их из словаря до тех пор, пока не сформируется 10 наиболее распространенных в тексте слов со смыслом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude stop words until 10 meaningful words not counted\n",
    "def present_top(words_dict: dict):\n",
    "    # may exclude all stop words form dictionary if it's needed, comment if with break\n",
    "    TOP_COUNT = 10\n",
    "\n",
    "    top_counter = 0\n",
    "    keys_to_delete = list()\n",
    "\n",
    "    print(TOP_COUNT, 'words frequently used in text:')\n",
    "    # check word key in dictionary is in stop words, append stop words to list, than remove from dictionary\n",
    "    for word_key in words_dict.keys():\n",
    "        if word_key in spacy.lang.en.stop_words.STOP_WORDS:\n",
    "            keys_to_delete.append(word_key)\n",
    "            continue\n",
    "\n",
    "        top_counter += 1\n",
    "        # represent meaningful words right away to avoid iterate through dictionary twice\n",
    "        print(word_key, words_dict[word_key])\n",
    "        if top_counter == TOP_COUNT:\n",
    "            break\n",
    "\n",
    "    # exclude stop words\n",
    "    for del_key in keys_to_delete:\n",
    "        words_dict.pop(del_key)\n",
    "\n",
    "    print(len(keys_to_delete), 'stop words were excluded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words frequently used in text:\n",
      "alice 9\n",
      "carroll 6\n",
      "story 4\n",
      "girl 3\n",
      "book 3\n",
      "literature 3\n",
      "character 3\n",
      "write 3\n",
      "child 3\n",
      "liddell 3\n",
      "15 stop words were excluded\n"
     ]
    }
   ],
   "source": [
    "present_top(spacy_unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
