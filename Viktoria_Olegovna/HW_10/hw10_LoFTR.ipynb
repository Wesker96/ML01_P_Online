{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 20836,
     "status": "ok",
     "timestamp": 1734555106711,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "s3V8c9occAZf",
    "outputId": "3da9ef09-2bd6-45a6-e1ca-5aa45e5ff34e"
   },
   "outputs": [],
   "source": [
    "!pip3 install kornia\n",
    "!pip3 install kornia_moons\n",
    "!pip3 install kaleido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtOm_cU6cWMw"
   },
   "source": [
    "2. Использовать решение на базе нейронных сетей. Любые идеи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108415,
     "status": "ok",
     "timestamp": 1734555233836,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "UQfyEC6zccS6",
    "outputId": "0b96a54c-bbec-4004-8af1-91fb550f0014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15494,
     "status": "ok",
     "timestamp": 1734555252012,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "Mlu-9M7XG-F5"
   },
   "outputs": [],
   "source": [
    "from kornia.feature import LoFTR\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1734555252014,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "rAHQWtqXIq43"
   },
   "outputs": [],
   "source": [
    "# function for vizualize cemera trajectory and direction\n",
    "def visualize_trajectory(rotation, positions, title='Camera motion'):\n",
    "    fig = gr.Figure()\n",
    "\n",
    "    # add trajectory trace\n",
    "    fig.add_trace(gr.Scatter3d(x=positions[:, 0], y=positions[:, 1], z=positions[:, 2],\n",
    "                               marker=dict(size=1.2, color='purple')))\n",
    "\n",
    "    # add camera orientation traces\n",
    "    for (p, r) in zip(positions, rotation):\n",
    "        point2 = p + 0.5 * r[:, 2]\n",
    "        fig.add_trace(gr.Scatter3d(x=[p[0], point2[0]], y=[p[1], point2[1]], z=[p[2], point2[2]],\n",
    "                                   mode='lines', line=dict(width=2, color='red')))\n",
    "\n",
    "    fig.update_layout(title=title, showlegend=False)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1734555252015,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "G6sfGxk-ccRO"
   },
   "outputs": [],
   "source": [
    "# use LoFTR matcher to get general points from two frames\n",
    "def process_imgs_LoFTR(matcher, input_dict: dict):\n",
    "    CONFIDENCE_TH = 0.85\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        corrs = matcher(input_dict)\n",
    "\n",
    "    confidence = corrs['confidence'].cpu().numpy()\n",
    "\n",
    "    del_indexes = list()\n",
    "    for i in range(len(confidence)):\n",
    "        if confidence[i] < CONFIDENCE_TH:\n",
    "            del_indexes.append(i)\n",
    "\n",
    "    kps1 = np.delete(corrs['keypoints0'].cpu().numpy(), del_indexes, axis=0)\n",
    "    kps2 = np.delete(corrs['keypoints1'].cpu().numpy(), del_indexes, axis=0)\n",
    "\n",
    "    return kps1, kps2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1734560841799,
     "user": {
      "displayName": "Виктория Лазько",
      "userId": "04673899877398873341"
     },
     "user_tz": -180
    },
    "id": "dhuvV6Y5ccOT"
   },
   "outputs": [],
   "source": [
    "# function for create camera trajectory by video\n",
    "def process_video_LoFTR(input_path: str):\n",
    "    global SCALE\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    # camera matrix\n",
    "    K = np.array([[3000, 0 , cap.get(cv2.CAP_PROP_FRAME_WIDTH) / (2 * SCALE)],\n",
    "                  [0, 3000, cap.get(cv2.CAP_PROP_FRAME_HEIGHT) / (2 * SCALE)],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    # create Local Feature Matching with Transformers\n",
    "    matcher = LoFTR(pretrained='outdoor')\n",
    "    matcher = matcher.eval().cuda()\n",
    "\n",
    "    # create_array with points of camera trajectory\n",
    "    trajectory = np.array([[0, 0, 0]])\n",
    "\n",
    "    # create general list with rotations matrix corresponds to each video frame\n",
    "    rotations_list = [np.zeros((3, 3))]\n",
    "\n",
    "    # camera positions\n",
    "    positions = [np.array([0, 0, 0])]\n",
    "\n",
    "    cam_matrix = np.eye(4)\n",
    "    T = np.eye(4)\n",
    "\n",
    "    prev_frame_cuda = None\n",
    "\n",
    "    while True:\n",
    "        is_success, frame = cap.read()\n",
    "\n",
    "        if not is_success:\n",
    "            break\n",
    "\n",
    "        # convert frame to one-dimential gray image, than resize\n",
    "        frame_gray = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),\n",
    "                                (int(frame.shape[0] / SCALE), int(frame.shape[1] / SCALE)),\n",
    "                                cv2.INTER_CUBIC)\n",
    "\n",
    "        # reshape image to get shape (batch x channels x H x W)\n",
    "        frame_gray = frame_gray.reshape(1, 1, frame_gray.shape[1],\n",
    "                                        frame_gray.shape[0])\n",
    "        # copy image to gpu and normalize\n",
    "        frame_cuda = torch.from_numpy(frame_gray).cuda() / 255.\n",
    "\n",
    "        if prev_frame_cuda is not None:\n",
    "            input_dict = {'image0': prev_frame_cuda, 'image1': frame_cuda}\n",
    "            kps1, kps2 = process_imgs_LoFTR(matcher, input_dict)\n",
    "\n",
    "            # calculate essential matrix to match camera positons between 2 frames\n",
    "            e_mat, mask = cv2.findEssentialMat(kps1, kps2, K, method=cv2.LMEDS,\n",
    "                                               threshold=1.)\n",
    "            _, R, t, _ = cv2.recoverPose(e_mat, kps1, kps2, K, mask=mask)\n",
    "\n",
    "            T[:3, :3] = R\n",
    "            T[:3, 3] = t.T\n",
    "\n",
    "            cam_matrix = np.dot(cam_matrix, T)\n",
    "            trajectory = np.vstack([trajectory, cam_matrix[:3, 3]])\n",
    "            rotations_list.append(cam_matrix[:3, :3])\n",
    "\n",
    "            positions.append(positions[-1] + np.dot(R, t).T[0])\n",
    "\n",
    "        # save current gray frame as previous to calculate matrix in next step\n",
    "        prev_frame_cuda = frame_cuda\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return rotations_list, trajectory, np.array(positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSSlT8-EccLJ"
   },
   "outputs": [],
   "source": [
    "video_path = '/content/drive/MyDrive/peleng-cources/HW_10/videos/video_5fps.mp4'\n",
    "data_folder = '/content/drive/MyDrive/peleng-cources/HW_10/saved_data'\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "\n",
    "SCALE = 2\n",
    "\n",
    "# get camera rotations and trajectory\n",
    "rotations_list, trajectory, positions = process_video_LoFTR(video_path)\n",
    "\n",
    "# visualize camera motion, get fps value from path\n",
    "start = video_path.rfind('_')\n",
    "end = video_path.find('fps')\n",
    "title = f'Camera motion, LoFTR, video fps = {video_path[start+1:end]}'\n",
    "visualize_trajectory(rotations_list, trajectory, title)\n",
    "\n",
    "# save camera rotations and trajectory to npz-file\n",
    "npz_filename = os.path.join(data_folder,\n",
    "                            f'data_LoFTR_LMEDS_{video_path[start+1:end]}fps.npz')\n",
    "np.savez(npz_filename, R=rotations_list, trajectory=trajectory,\n",
    "         positions=positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7haEco-YEJ7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
