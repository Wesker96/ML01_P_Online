{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать полученные знания в части обучения моделей для обучения и подбора параметров в задачах из предыдущих ДЗ на выбор (мфо, задача с тем возьмёт ли человек кредит или нет)\n",
    "В частности использовать:\n",
    "\n",
    "\n",
    "GaussianNB\n",
    "LogisticRegression \n",
    "Linear + PolynomialFeatures.\n",
    "RandomForestClassifier \n",
    "При обучении использовать make_pipeline\n",
    "GridSearchCV для поиска параметров \n",
    "Посчитать матрики (f1 + точность + AUC). \n",
    "\n",
    "\n",
    "\n",
    "Откроем файл и создадим датафрейм для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, auc,roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "with open('credit_train.csv', newline='', encoding='Windows-1251') as f:\n",
    "      \n",
    "    str = f.read().replace(\",\", \".\" ) \n",
    "    str = str.replace(\";\",\",\")    \n",
    "    with open('train_ready.csv','w',  encoding='Windows-1251') as file2:    \n",
    "        file2.write(str)\n",
    "        \n",
    "df = pd.read_csv(\"train_ready.csv\",encoding='Windows-1251' ,on_bad_lines='skip',            \n",
    "            usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных. Удалим слова Область, край и тд из Региона проживания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170746\n",
      "161331\n"
     ]
    }
   ],
   "source": [
    "bad_words = ['РЕСП','РЕСП.','РЕСПУБЛИКА', 'САХА', 'ОБЛ','АОБЛ', 'АВТОНОМНЫЙ ОКРУГ','ЮГРА', 'ЧУВАШИЯ', 'ФЕДЕРАЛЬНЫЙ ОКРУГ', 'АО', 'ОБЛАСТЬ', 'КРАЙ', 'Г', 'Ю', 'СЕВ.', 'СЕВЕРНАЯ', 'АЛАНИЯ', ' ']\n",
    "change_dict = {'ОБЛАСТЬ':'','ОБЛ':'','КРАЙ':'','АО':'','АВТОНОМНЫЙ ОКРУГ':'','РЕСПУБЛИКА':'','РЕСП.':'','РЕСП':'','САХА/':'','САХА ':'','ЮГРА':'','-Ю':''}\n",
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df = df.replace(to_replace =change_dict, regex = True)\n",
    "df['living_region'] = df['living_region'].str.replace(\" \", \"\")\n",
    "df['living_region'] = df['living_region'].str.replace(r'[^а-яА-Яa-zA-Z\\s]', '', regex=True)\n",
    "df2 = df# for one hot encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальные переменные в  числовые методом LabelEncoder. Разделим данные методом TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        client_id  gender   age  marital_status  job_position  credit_sum  \\\n",
      "7               8       0  26.0               3            12    47878.00   \n",
      "9              10       0  32.0               3            12    26268.00   \n",
      "10             11       1  26.0               2            12    16793.00   \n",
      "12             13       1  37.0               2            12    42289.00   \n",
      "13             14       1  43.0               2             5    57567.00   \n",
      "...           ...     ...   ...             ...           ...         ...   \n",
      "170741     170742       0  27.0               3            12    64867.00   \n",
      "170742     170743       0  24.0               2            12    17640.00   \n",
      "170743     170744       0  31.0               3            12    27556.47   \n",
      "170744     170745       0  53.0               1             8     6189.00   \n",
      "170745     170746       1  49.0               2            12    12787.00   \n",
      "\n",
      "        credit_month  tariff_id  score_shk  education  living_region  \\\n",
      "7                 10       1.10   0.512525          1             52   \n",
      "9                 10       1.10   0.465026          1             82   \n",
      "10                14       1.00   0.445430          3             73   \n",
      "12                10       1.60   0.691609          3              6   \n",
      "13                10       1.10   0.341164          1             94   \n",
      "...              ...        ...        ...        ...            ...   \n",
      "170741            12       1.10   0.535257          1             84   \n",
      "170742             6       1.60   0.573287          3             74   \n",
      "170743            10       1.32   0.416098          1             67   \n",
      "170744            12       1.10   0.482595          3             63   \n",
      "170745            10       1.10   0.316087          1             52   \n",
      "\n",
      "        monthly_income  credit_count  overdue_credit_count  open_account_flg  \n",
      "7              60000.0           3.0                   0.0                 0  \n",
      "9              39500.0           7.0                   0.0                 0  \n",
      "10             36000.0           2.0                   0.0                 0  \n",
      "12             70000.0           1.0                   0.0                 0  \n",
      "13             60000.0           7.0                   0.0                 0  \n",
      "...                ...           ...                   ...               ...  \n",
      "170741         40000.0           6.0                   0.0                 0  \n",
      "170742         30000.0           1.0                   0.0                 0  \n",
      "170743         40000.0           1.0                   0.0                 0  \n",
      "170744         31000.0           2.0                   0.0                 0  \n",
      "170745         40000.0           3.0                   0.0                 0  \n",
      "\n",
      "[161331 rows x 15 columns]\n",
      " fit:  <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "RandomForestClassifier accuracy: 0.831,  f1:  0.830854096938143,  AUC:  0.7172070190015323\n",
      " fit:  <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "KNeighborsClassifier accuracy: 0.837,  f1:  0.8366183215569605,  AUC:  0.5601135508298003\n",
      " fit:  <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "GaussianNB accuracy: 0.835,  f1:  0.8350068179000868,  AUC:  0.5944974662945027\n",
      " fit:  <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "LogisticRegression accuracy: 0.837,  f1:  0.8368042642865997,  AUC:  0.6135572014428999\n"
     ]
    }
   ],
   "source": [
    "for col in ['gender', 'marital_status', 'job_position', 'education','living_region']:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "print(df)\n",
    "# Разделим датафрейм на входные и выходные данные:\n",
    "X = df.drop('open_account_flg', axis=1)\n",
    "y = df['open_account_flg']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
    "\n",
    "#Создадим список классификаторов:\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=30,max_features = 11) ,\n",
    "    KNeighborsClassifier(n_neighbors = 100, weights ='distance',n_jobs = 4),\n",
    "    GaussianNB(var_smoothing =2e-9),\n",
    "    LogisticRegression(penalty = 'l2',C = 1.1, random_state=14,solver = 'newton-cholesky')        \n",
    "    ]\n",
    "    \n",
    "# Переберем все классификаторы:\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\" fit: \",type(clf))\n",
    "    # Сделаем прогнозирование результата:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Выведем вероятность нуля или единицы для вычисления AUC:\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]  \n",
    "    # Рассчитаем fpr, tpr, для вычисления AUC:\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score, pos_label=None)\n",
    "    # Рассчитаем  точность, ф1 меру и АУС метрику:\n",
    "    print(f\"{clf.__class__.__name__} accuracy: {accuracy_score(y_test, y_pred):.3f},  f1:  {f1_score(y_test, y_pred, average='micro')},  AUC:  {auc(fpr, tpr) }\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы. \n",
    "\n",
    "RandomForestClassifier Работает медленно. По метрике AUC дает самый высокий результат. Увеличение количества деревьев более 30 не улучшает результат.\n",
    "KNeighborsClassifier - на результат влияет только количество соседей. После 100 перестает давать эффект. Работает очень быстро.\n",
    "GaussianNB   - результат слабый, работает очень быстро. Параметры не улучшают результат в сравнении с дефолтными.\n",
    "LogisticRegression - серьезно улучшает результат AUC параметр solver = newton-cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим обработку ONEHOTENCODER. Все классификаторы здесь аналогичны предыдущему фрагменту. GaussianNB здесь не работает,\n",
    "ругается на то, что матрица SPARCE, а не DENSE, что нормально для ONEHOTENCODER. Также здесь применим Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fit:  <class 'sklearn.pipeline.Pipeline'>\n",
      "RandomForestClassifier accuracy: 0.835,  f1:  0.8353787033593653,  AUC:  0.7046758078510915\n",
      " fit:  <class 'sklearn.pipeline.Pipeline'>\n",
      "KNeighborsClassifier accuracy: 0.838,  f1:  0.8383537870335936,  AUC:  0.6812985261740852\n",
      " fit:  <class 'sklearn.pipeline.Pipeline'>\n",
      "LogisticRegression accuracy: 0.840,  f1:  0.8395934052311887,  AUC:  0.643713929954489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Разделим фичи на численные и категориальные. Создадим 2 пайплайна для каждого из них. \n",
    "\n",
    "numeric_features = ['client_id', 'age', 'credit_sum', 'credit_month','tariff_id', 'score_shk', 'monthly_income','credit_count','overdue_credit_count']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = ['gender', 'marital_status', 'job_position', 'education','living_region']\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        #(\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "#Создадим препрроцессор для отдельной обработки численных и категориальных столбцов.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "# Создадим пайплайн для подстановки плассификаторов:\n",
    "pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\"classifier\", RandomForestClassifier(n_estimators=70)]\n",
    ")\n",
    "#Разделим датафрейм на входные и выходные параметры модели:\n",
    "X = df2.drop('open_account_flg', axis=1)\n",
    "y = df2['open_account_flg']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,shuffle=True, random_state=70)\n",
    "\n",
    "# Создадим те же классификаторы, что и при использовании LabelEncoder\n",
    "classifiers = [    \n",
    "    RandomForestClassifier(n_estimators=30,max_features = 11) ,\n",
    "    KNeighborsClassifier(n_neighbors = 100, weights ='distance',n_jobs = 4),\n",
    "    #GaussianNB(var_smoothing =2e-9),\n",
    "    LogisticRegression(penalty = 'l2',C = 1.1, random_state=14,solver = 'newton-cholesky')     \n",
    "    ]\n",
    "\n",
    "# Создадим цикл для перебора классификаторов.\n",
    "for current_clf in classifiers:\n",
    "    pipe.steps.insert(1,['classifier',current_clf])    \n",
    "    clf = Pipeline(pipe.steps[0:2])    \n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\" fit: \",type(clf))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score, pos_label=None)\n",
    "    print(f\"{current_clf.__class__.__name__} accuracy: {accuracy_score(y_test, y_pred):.3f},  f1:  {f1_score(y_test, y_pred, average='micro')},  AUC:  {auc(fpr, tpr) }\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: Наилучший результат по AUC дал RandomForestClassifier.\n",
    "По точности наилучший результат у LogisticRegression, однако в связи с неравномерно распределенным результатом на него нельзя ориентироваться.\n",
    "Также стоит отметить, что ONEHOTENCODER по сравнению с LabelEncoder не дает улучшения параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Так как метрики получены низкого качества, в качестве самопроверки применим код на выборке ирисов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy: 1.000,  f1:  0.8351804841805461\n",
      "KNeighborsClassifier accuracy: 1.000,  f1:  0.8351804841805461\n",
      "GaussianNB accuracy: 1.000,  f1:  0.8351804841805461\n",
      "LogisticRegression accuracy: 1.000,  f1:  0.8351804841805461\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv(\"iris.csv\",encoding='Windows-1251' ,on_bad_lines='skip',\n",
    "            #index_col='client_id' ,\n",
    "            usecols=[0,1,2,3,4]\n",
    "            )\n",
    "\n",
    "iris['target'] = LabelEncoder().fit_transform(iris['target'])\n",
    "X = iris.drop('target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=30,max_features = 11) ,\n",
    "    KNeighborsClassifier(n_neighbors = 100, weights ='distance',n_jobs = 4),\n",
    "    GaussianNB(var_smoothing =2e-9),\n",
    "    LogisticRegression(penalty = 'l2',C = 1.1, random_state=14,solver = 'newton-cholesky')        \n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]    \n",
    "   \n",
    "    print(f\"{clf.__class__.__name__} accuracy: {accuracy_score(y_test, y_pred):.3f},  f1:  {f1_score(yD_test, yD_pred, average='micro')}\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: Полученный код на выборке ирисов дает точность 100 процентов по причине простоты определени параметров. Для улучшения результата по выборке кредитного скоринга необходимо дальнейшая работа с классификаторами или их параметрами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
