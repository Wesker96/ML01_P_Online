{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Для любых пар изображений которые имеют общее поле зрения (две фотографии сделанные с телефона который был повернут на определенный угол - любой лишь бы было 20+% перекрытия)\n",
    "Рассчитать матрицу афинного преобразования из одной системы координат в другую. Выполнить разложение данной матрицы и посчитать явно угол поворота, вектор переноса и скалирования. \n",
    "Выполнить обратное преобразование - получить афинную матрицу заново. \n",
    "\n",
    "https://www.youtube.com/@Vaska_pilot/videos\n",
    "\n",
    "2) Взять любую видеопоследовательность (желательно вид сверху) - например полет дрона. Можете скачать из  интернета или взять что то с работы. \n",
    "- Зафиксировав точку (например центр экрана) выполнить стабилизацию данной точки с использованием матрицы афинного преобразования \n",
    "(считая матрицу между кадрами вы всегда сможете понять где именно находится точка на изображении, а по отклонению самой точки вы можете определить точность самого алгоритма).\n",
    "Не берите 4к - долго считать, HD будет достаточно\n",
    "- Посчитать расстояние между точками и ошибку в пикселях.\n",
    "- Попробуйте добавить шум к изображению, посмотрите как меняется точность (положение точки). \n",
    "- Добавьте фильтр к изображению для улучшения контрастности (любой который найдете).\n",
    "- Оцените как влияет выбор метода определения матрицы афинного преобразования - например estimateAffine2D и его аналоги (аналоги найдите самии).\n",
    "- Оцените как влияет выбор детектора/дескриптора особых точек на результат. Какой метод даст лучший и самый быстрый результат? \n",
    "\n",
    "3) LoFTR  - любой другой, сравнить с готовыми решениями. \n",
    "\n",
    "Напишите Вывод. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача:\n",
    "- Попробовать афинные матрицы в изображениях и при слежении за точкой в видео\n",
    "\n",
    "### Решение:\n",
    "- Лучший дескриптор который подошел, это SIFT, возможно SURF будет быстрее но он в NON_FREE_VERSION OpenCV как получиться пересобрать попробую.\n",
    "- Попробовал два дескриптора на нейронках это LoFTR и SuperPoint. В суперпоинт преобразую кадры позже в видео\n",
    "### Вывод: \n",
    "- Попробую еще досатать какие-нибудь метрики и сделать нормальный вывод\n",
    "### Вывод программ:\n",
    "<image src=\"plot_without_axes.png\" alt=\"SIFT Дескриптор\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Считает афинную матрицу и находит любую точку на изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_matches(image1, kp1, image2, kp2, match):\n",
    "    \n",
    "    image_matches = cv2.drawMatches(image1, kp1, image2, kp2, match, None, flags=2)\n",
    "    plt.figure(figsize=(16, 6), dpi=200,)\n",
    "    plt.imshow(image_matches)\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.savefig('plot_without_axes.png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "def filter_matches_distance(matches, dist_threshold):\n",
    "    filtered_match = []\n",
    "    for m, n in matches:\n",
    "        if m.distance <= dist_threshold*n.distance:\n",
    "            filtered_match.append(m)\n",
    "\n",
    "    return filtered_match\n",
    "\n",
    "def match_features(des1, des2, matching='BF', detector='sift', sort=True, k=2):\n",
    "    if matching == 'BF':\n",
    "        if detector == 'sift':\n",
    "            matcher = cv2.BFMatcher_create(cv2.NORM_L2, crossCheck=False)\n",
    "        elif detector == 'orb':\n",
    "            matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING2, crossCheck=False)\n",
    "        matches = matcher.knnMatch(des1, des2, k=k)\n",
    "    elif matching == 'FLANN':\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = matcher.knnMatch(des1, des2, k=k)\n",
    "    if sort:\n",
    "        matches = sorted(matches, key = lambda x:x[0].distance)\n",
    "    return matches\n",
    "\n",
    "def extract_features(image, detector, mask=None):\n",
    "    if detector == 'sift':\n",
    "        det = cv2.SIFT_create()\n",
    "    elif detector == 'orb':\n",
    "        det = cv2.ORB_create()\n",
    "    elif detector == 'surf':\n",
    "        det = cv2.xfeatures2d.SURF_create()\n",
    "    kp, des = det.detectAndCompute(image, mask)\n",
    "    return kp, des\n",
    "\n",
    "img0 = cv2.imread(\"IMG_1.JPG\")\n",
    "img1 = cv2.imread(\"IMG_2.JPG\")\n",
    "img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kp0, des0 = extract_features(img0, 'sift')\n",
    "kp1, des1 = extract_features(img1, 'sift')\n",
    "matches = match_features(des0, des1, matching='BF', detector='sift', sort=True)\n",
    "print('Number of matches before filtering:', len(matches))\n",
    "matches = filter_matches_distance(matches, 0.4)\n",
    "print('Number of matches after filtering:', len(matches))\n",
    "visualize_matches(img0, kp0, img1, kp1, matches)\n",
    "\n",
    "def decompose_affine_matrix(affine):\n",
    "    if affine.shape != (3, 3) or affine.dtype != np.float64:\n",
    "        raise ValueError(\"Invalid input matrix. Must be a 3x3 double matrix.\")\n",
    "\n",
    "    R = affine[:2, :2]\n",
    "    U, W, Vt = np.linalg.svd(R)\n",
    "\n",
    "    rotation = np.dot(U, Vt)\n",
    "    scaling = np.diag(W)\n",
    "    translation = affine[:2, 2:]\n",
    "\n",
    "    return rotation, translation, scaling\n",
    "\n",
    "def estimate_partial_transform(cur_matched_kp, prev_matched_kp ,method):\n",
    "    \n",
    "    transform = cv2.estimateAffine2D(np.array(prev_matched_kp),\n",
    "                                           np.array(cur_matched_kp),method=method)[0] #Тут как бы можно играться с тем как будут фильтроватся точки \n",
    "                                                                                          #cv2.LMEDS один из параметров который напрямую влияет    \n",
    "    if transform is not None:\n",
    "        dx = transform[0, 2]\n",
    "        dy = transform[1, 2]\n",
    "        da = np.arctan2(transform[1, 0], transform[0, 0])\n",
    "    else:\n",
    "        dx = dy = da = 0\n",
    "\n",
    "    return [dx, dy, da], transform\n",
    "\n",
    "src_pts = np.float32([kp0[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([kp1[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "m , M = estimate_partial_transform(src_pts,dst_pts, cv2.LMEDS)\n",
    "afine_transform_matrix =  np.append(M,np.array([0,0,1])).reshape(3,3)\n",
    "print(m)\n",
    "print(M)\n",
    "print(afine_transform_matrix)\n",
    "\n",
    "def apply_affine_transformation(point, affine_matrix):\n",
    "    \n",
    "    point_homogeneous = np.array([point[0], point[1], 1])\n",
    "    transformed_point = np.dot(affine_matrix, point_homogeneous)\n",
    "    return transformed_point[:2]\n",
    "\n",
    "\n",
    "if img0 is None or img1 is None:\n",
    "    print(\"Ошибка: не удалось загрузить изображения. Проверьте пути.\")\n",
    "    exit()\n",
    "\n",
    "point = (2000, 2400)\n",
    "\n",
    "new_point = apply_affine_transformation(point, afine_transform_matrix)\n",
    "\n",
    "cv2.circle(img1, point, 30, (0, 255, 0), -1)\n",
    "\n",
    "cv2.circle(img0, (int(new_point[0]), int(new_point[1])), 20, (0, 0, 255), -1)\n",
    "cv2.namedWindow(\"f\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"f\", 600, 1200)\n",
    "cv2.namedWindow(\"s\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"s\", 800, 600)\n",
    "\n",
    "cv2.imshow(\"f\", img0)\n",
    "cv2.imshow(\"s\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видео со слежением [Видео на гугл диск](https://drive.google.com/drive/folders/1DRqweP4Z85FdMhfaZ--JdALb2ot8Raxe?usp=sharing)\n",
    "### LoFTR Дискриптор\n",
    "<image src=\"loftr_match.png\" alt=\"LoFTR Дескриптор\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для множества точек использовал https://github.com/magicleap/SuperPointPretrainedNetwork"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
