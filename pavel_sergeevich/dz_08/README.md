

#### Задание

Провести анализ данных, внести необходимые корректировки. Подготовить данные для модели.

1. Обработать пропуски.
2. Оценить выбросы.
3. Корреляция.
4. Тест на нормальность распределения.
5. Масштабировать данные.

**Дополнительная задача**: есть данные, что тест на болезнь дает результат с вероятностью в 98%.
Число больных в популяции у нас 1%. Вопрос - с какой вероятностью положительный тест будет положительным при случайном тестировании.  

#### Данные

 - учебные данные: data_set.csv - банковские данные
 - ~~датасет с городами России. Взят [отсюда](https://github.com/arbaev/russia-cities)~~

#### Анализ данных

Краткий метаанализ учебного датасета:
```log
Количество фич в датасете: 15
Количество строк в датасете: 170746

Названия фич (колонки):
    - client_id
    - gender
    - age
    - marital_status
    - job_position
    - credit_sum
    - credit_month
    - tariff_id
    - score_shk
    - education
    - living_region
    - monthly_income
    - credit_count
    - overdue_credit_count
    - open_account_flg

Используемая память (MB): 19.54
```

В анализе колонка "client_id" опущена, т.к. не несет полезной информации в данном контексте. Оценка пропусков:

```log
Справка по пропускам в датасете:
client_id                  0
gender                     0
age                        3
marital_status             3
job_position               0
credit_sum                 2
credit_month               0
tariff_id                  0
score_shk                  7
education                  5
living_region            192
monthly_income             5
credit_count            9230
overdue_credit_count    9230
open_account_flg           0
dtype: int64

Число удаленных строк - 9415
Всего потери данных на пропусках составляют: 5.51%
```

Как видно, количество пропущенных данных не большое и по отношению к целым данным составляют всего 5.51%, что не является существенной частью данных, ввиду чего эти пропуски мы удаляем. Пропуски в колонках *credit_count* и *overdue_credit_count* с большего совпадают - есть зависимость, возможно, есть зависимость с другими колонками? Построим гистограммы пропусков колонок по административным единицам, возможно есть что-то интересное.

![[hist_more_100_0.png]](pic/hist_more_100_0.png)
![[hist_more_100_1.png]](pic/hist_more_100_1.png)
*Рис 1 - Гистограммы пропусков по населенным пунктам. Выведены населенные пункты, частота упоминания которых больше 100. Получилось 24 населенных пункта (из 195). Гистограммы для overdue_credit_count (вверху) и credit_count (внизу) идентичны.*

Как и ожидалось, Москва, Московская область и Санкт-Петербург ошибаются со сбором данных чаще всего. Здесь мы также видим и еще одну особенность набора данных - некорректные наименования населенных пунктов, например "Москва" и "Москва Г" это все та же Москва. К этой особенности вернемся чуть позже.

Рассмотрим очищенные данные от пропусков. Начнем (потому что при первичном анализе значения этих колонок свелись к их небольшому набору) с колонок *open_account_flag* и *overdue_credit_count* - построим для них гистограммы и ящики с усами.

![[discrete_value.png]](pic/discrete_value.png)
Рис 2 - Гистограммы и ящики с усами колонок *open_account_flag* и *overdue_credit_count*

Из графиков видно, что значения в *open_account_flag* в целом бинарные - либо 1, либо 0, причем нулей значительно меньше, порядка ~17%. Будем считать, что эти данные валидны и дополнительной обработки для них не нужно. Что касается *overdue_credit_count*, то видно, что подавляющее количество значение соответствует значению 0, а на остальные приходится порядка ~5% (из них на значение 1 - 4.7%). Сложно сказать, нужно ли их убирать или нет, т.к. не понятна важность этих данных (не определена целевая задача). 

Ниже приведены графики для остальных колонок.

![[boxplot.png]](pic/boxplot.png)
![[tariff_id.png]](pic/tariff_id.png)
Рис 3 - Ящики с усами для остальных колонок

Из графиков выше видно, что во всех колонках есть выбросы. Уберем из них выбросы воспользовавшись формулой межквартильных расстояний. Ниже приведена картинка поясняющая межквартильные расстояния и их отображение на диаграмме ящика с усами.

![[wiki.png]](pic/wiki.png)
Рис 4 - Пояснение построения усов диаграммы ящика с усами. Все что дальше "усов" считается выбросом. Картинка взята из [википедии](https://ru.wikipedia.org/wiki/%D0%AF%D1%89%D0%B8%D0%BA_%D1%81_%D1%83%D1%81%D0%B0%D0%BC%D0%B8)

Результат удаления выбросов:

```log
Количество индексов на удаление со всех столбцов: 44732
Количество уникальных индексов на удаление: 39126
Количество выбросов: 39126 (24.25%)
Данных в наборе осталось: 122205
```

Что ж, нам не повезло, выбросы совпали по строкам только 12.5%. Поэтому данных стало существенно меньше - 122205 против 170746 что были сначала.

Далее, что нам нужно сделать - обработать категориальные данные, масштабировать данные и провести тест на нормальность данных. Для теста на нормальность использовался критерий согласия Пирсона. По итогу, данные не соответствуют нормальному распределению:

```log
Отклонить гипотезу о нормальности колонки age
Отклонить гипотезу о нормальности колонки credit_sum
Отклонить гипотезу о нормальности колонки credit_month
Отклонить гипотезу о нормальности колонки score_shk
Отклонить гипотезу о нормальности колонки monthly_income
Отклонить гипотезу о нормальности колонки credit_count
Отклонить гипотезу о нормальности колонки tariff_id
```

Построим корреляцию

![[corr.png]](pic/corr.png)
Рис 5 - Корреляционная матрица

Из графика видно, что только колонки *tariff_id* и *score_shk* имеют слабую корреляцию.

#### Выводы

 - Обработка пропусков путем их отбрасывания уменьшило объем данных на 5.51%
 - Последующая обработка выбросов дополнительно уменьшило объем данных на 24.25%
 - Данные тесты на нормальность не прошли
 - Исходя из корреляционной матрицы только колонки *tariff_id* и *score_shk* имеют слабую корреляцию.